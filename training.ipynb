{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEG = False\n",
    "TRAIN_CLASS = False\n",
    "TRAIN_STAR = True\n",
    "TRAIN_STAR_3D = False\n",
    "colab = False\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab = True\n",
    "    import os\n",
    "    import sys\n",
    "    drive.mount('/content/drive/')\n",
    "    %cd /content/drive/MyDrive/prl_seg\n",
    "except ImportError as e:\n",
    "    pass\n",
    "\n",
    "if colab:\n",
    "    try:\n",
    "        import monai\n",
    "    except ImportError as e:\n",
    "        ! pip install monai\n",
    "    try:\n",
    "        import torcheval\n",
    "    except ImportError as e:\n",
    "        ! pip install torcheval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1\n",
      "CUDA Available: False\n",
      "CUDA Version: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from torcheval.metrics import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    "    BinaryF1Score,\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss, GeneralizedWassersteinDiceLoss, GeneralizedDiceLoss, DiceCELoss\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from config import *\n",
    "from pylib import training\n",
    "from pylib.models import resnet, unet, resnet3d, unet3d\n",
    "from pylib.datasets.lazy_dataset import LazyDataset\n",
    "\n",
    "if colab:\n",
    "    from monai.networks.nets import UNet\n",
    "    from monai.networks.layers import Norm\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x - Lesion segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation training parameters\n",
    "BATCH_SIZE_SEG = 16\n",
    "LEARNING_RATE_SEG = 0.005\n",
    "EPOCHS_SEG = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SEG:\n",
    "    train_seg_data = torch.load(PATH_TRAIN_LESION_SEG_DATASET, weights_only=False) \n",
    "    val_seg_data = torch.load(PATH_VAL_LESION_SEG_DATASET, weights_only=False) \n",
    "        #test_data = torch.load(PATH_TEST_DATASET, weights_only=False) \n",
    "\n",
    "\n",
    "    train_seg_loader = DataLoader(dataset=train_seg_data, batch_size=BATCH_SIZE_SEG, shuffle=True)\n",
    "    val_seg_loader = DataLoader(dataset=val_seg_data, batch_size=BATCH_SIZE_SEG, shuffle=True)\n",
    "    #test_loader = DataLoader(dataset=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SEG:\n",
    "    all_labels = torch.stack([label for _, label in train_seg_data])\n",
    "    n_lesion_pixels = torch.sum(all_labels)\n",
    "    n_total_pixels = all_labels.numel()\n",
    "    #weight = negative/positive\n",
    "    weight = 1 - torch.tensor(n_lesion_pixels/n_total_pixels)\n",
    "    weight = weight.to(DEVICE)\n",
    "    print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SEG:\n",
    "    bin_unet = unet.PRLUNET(n_channels=1, n_classes=1)\n",
    "    bin_unet = bin_unet.to(DEVICE)\n",
    "\n",
    "    optimizer = Adam(bin_unet.parameters(), lr=LEARNING_RATE_SEG)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "\n",
    "    trainer = training.Trainer(OUT_DIR)\n",
    "\n",
    "    trainer(\n",
    "        bin_unet,\n",
    "        train_loader=train_seg_loader,\n",
    "        val_loader=val_seg_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        lr=LEARNING_RATE_SEG,\n",
    "        batch_size=BATCH_SIZE_SEG,\n",
    "        epochs = EPOCHS_SEG,\n",
    "        device=DEVICE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x - Classification of PRLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification training parametersÂ¨\n",
    "BATCH_SIZE_CLASS = 64\n",
    "LEARNING_RATE_CLASS = 1e-5\n",
    "EPOCHS_CLASS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_CLASS:\n",
    "    train_class_data = torch.load(PATH_3D_TRAIN_PRL_CLASS_DATASET, weights_only=False)\n",
    "    val_class_data = torch.load(PATH_3D_VAL_PRL_CLASS_DATASET, weights_only=False)\n",
    "\n",
    "    train_class_loader = DataLoader(dataset=train_class_data, batch_size=BATCH_SIZE_CLASS, shuffle=True)\n",
    "    val_class_loader = DataLoader(dataset=val_class_data, batch_size=BATCH_SIZE_CLASS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_class_data))\n",
    "# print(len(val_class_data))\n",
    "# print([i for i in val_class_data[:][1] if i == 0].count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_CLASS:\n",
    "    all_labels = torch.stack([label for _, label in train_class_data])\n",
    "    n_prls = torch.sum(all_labels)\n",
    "    n_negatives = all_labels.numel() - n_prls\n",
    "    #weight = negative/positive\n",
    "    weight = torch.tensor(n_negatives/n_prls).to(DEVICE)\n",
    "    weight = weight.to(DEVICE)\n",
    "    print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if TRAIN_CLASS:\n",
    "    resnet_3d = resnet3d.ResNet3d(n_channels = 1, n_classes=1)\n",
    "    resnet_3d = resnet_3d.to(DEVICE)\n",
    "\n",
    "    optimizer = Adam(resnet_3d.parameters(), lr=LEARNING_RATE_CLASS)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "    trainer = training.Trainer(OUT_DIR)\n",
    "\n",
    "    trainer(\n",
    "        resnet_3d,\n",
    "        train_loader=train_class_loader,\n",
    "        val_loader=val_class_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        lr=LEARNING_RATE_CLASS,\n",
    "        batch_size=BATCH_SIZE_CLASS,\n",
    "        epochs = EPOCHS_CLASS,\n",
    "        device=DEVICE,\n",
    "        metrics=[BinaryAccuracy(), BinaryF1Score()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x - Semantic classification of SWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_STAR = 32\n",
    "EPOCHS_STAR = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_STAR:\n",
    "    print(DIR_TRAIN_SWI_DATASET)\n",
    "    train_val_star_data = LazyDataset(DIR_TRAIN_SWI_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_STAR:\n",
    "    n_background = 0\n",
    "    n_lesions = 0\n",
    "    n_prls = 0\n",
    "    for _, _, label in train_val_star_data:\n",
    "        n_background += torch.sum(label[:, 0]).item()\n",
    "        n_lesions += torch.sum(label[:, 1]).item()\n",
    "        n_prls += torch.sum(label[:, 2]).item()\n",
    "\n",
    "    print(f\"n background: {n_background}, n lesions: {n_lesions}, n prls: {n_prls}\")\n",
    "\n",
    "    n_total =  n_lesions + n_prls\n",
    "    weight = torch.tensor([n_total / n_lesions, n_total / n_prls]).to(DEVICE)\n",
    "    print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_k_fold = False\n",
    "lrs = [2e-4]\n",
    "if TRAIN_STAR:\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    n_prls_per_patient = torch.tensor([torch.sum(label[:, 2]) for _, _, label in train_val_star_data])\n",
    "    median_n_prls = torch.median(n_prls_per_patient).item()\n",
    "    print(f\"Median number of PRLs (pixels) per patient: {median_n_prls}\")\n",
    "    k_fold_split = torch.where(n_prls_per_patient > median_n_prls, 1, 0).numpy()\n",
    "\n",
    "    print(f\"Number of patients with n PRLs > median: {k_fold_split.sum()}\")\n",
    "    print(f\"Number of patients with n PRLs =< median: {len(k_fold_split) - k_fold_split.sum()}\")\n",
    "\n",
    "    best_fold = 3\n",
    "    best_train_idx, best_val_idx  = [data for data in skf.split(train_val_star_data, k_fold_split)][best_fold]\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_val_star_data, k_fold_split) if run_k_fold else [(best_train_idx, best_val_idx)]):\n",
    "        print(f\"Fold {fold + 1}/{5}\") if run_k_fold else print(f\"Using Best Fold {best_fold + 1}/{5}\")\n",
    "        print(f\"Train idx: {train_idx} | Val idx: {val_idx}\")\n",
    "        for lr in lrs:\n",
    "            print(f\"Using Learning Rate {lr}\")\n",
    "\n",
    "            prl_seg_unet = unet.PRLUNet(n_channels=1, n_classes=3)\n",
    "\n",
    "            optimizer = Adam(prl_seg_unet.parameters(), lr=lr, weight_decay=1e-5)\n",
    "            loss_fn = DiceLoss(include_background=False, sigmoid = True, weight = weight)\n",
    "\n",
    "\n",
    "            train_subset = Subset(train_val_star_data, train_idx)\n",
    "            val_subset = Subset(train_val_star_data, val_idx)\n",
    "\n",
    "            # Combine the images and labels from the subsets into a single tensor\n",
    "            train_mags = torch.cat([img for img, _, _ in train_subset])\n",
    "            train_phases = torch.cat([img for _, img, _ in train_subset])\n",
    "            train_labels = torch.cat([label for _, _, label in train_subset])\n",
    "\n",
    "            val_mags = torch.cat([img for img, _, _ in val_subset])\n",
    "            val_phases = torch.cat([img for _, img, _ in val_subset])\n",
    "            val_labels = torch.cat([label for _, _, label in val_subset])\n",
    "\n",
    "\n",
    "            train_subset = TensorDataset(train_mags, train_phases, train_labels)\n",
    "            val_subset = TensorDataset(val_mags, val_phases, val_labels)\n",
    "\n",
    "            train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE_STAR, shuffle=True)\n",
    "            val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE_STAR, shuffle=False)\n",
    "\n",
    "            losses_train, losses_val = training.train_prl_seg_unet(prl_seg_unet,\n",
    "                        train_loader=train_loader,\n",
    "                        val_loader=val_loader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=EPOCHS_STAR,\n",
    "                        device=DEVICE,\n",
    "                        save_path=os.path.join(OUT_DIR, f\"prl_unet_lr_{lr}.pt\"),\n",
    "                        save_last_epoch_val = True,\n",
    "                        save_last_epoch_val_path=os.path.join(OUT_DIR, f\"prl_unet_lr_{lr}_last_epoch_val.pt\"),\n",
    "                        reduce_lr_on_plateau=False,\n",
    "                        validation_interval=EPOCHS_STAR\n",
    "                )\n",
    "            torch.save(torch.tensor(losses_train), os.path.join(OUT_DIR, f\"losses_train_lr_{lr}_fold_{fold}.pt\"))\n",
    "            torch.save(torch.tensor(losses_val), os.path.join(OUT_DIR, f\"losses_val_lr_{lr}_fold_{fold}.pt\"))\n",
    "\n",
    "\n",
    "            test_data = LazyDataset(DIR_TEST_SWI_DATASET)\n",
    "            test_loader = DataLoader(test_data, batch_size=BATCH_SIZE_STAR, shuffle=False)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_STAR:\n",
    "    test_data = LazyDataset(DIR_TEST_SWI_DATASET)\n",
    "\n",
    "    test_mags = torch.cat([img for img, _, _ in test_data])\n",
    "    test_phases = torch.cat([img for _, img, _ in test_data])\n",
    "    test_labels = torch.cat([label for _, _, label in test_data])\n",
    "\n",
    "    test_subset = TensorDataset(test_mags, test_phases, test_labels)\n",
    "    test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE_STAR, shuffle=False)\n",
    "\n",
    "    prl_seg_unet.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_phases, all_mags, all_labels, all_preds = [], [], [], []\n",
    "        for i, (mags, phases, labels) in enumerate(test_loader):\n",
    "            mags = mags.to(DEVICE)\n",
    "            phases = phases.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = prl_seg_unet(mags, phases)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            preds = preds > 0.5\n",
    "\n",
    "            all_phases.append(phases.cpu())\n",
    "            all_mags.append(mags.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "        all_phases = torch.cat(all_phases, dim=0)\n",
    "        all_mags = torch.cat(all_mags, dim=0)\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "    \n",
    "    torch.save(TensorDataset(all_mags, all_phases, all_labels, all_preds), f\"prl_unet_lr_{lr}_last_epoch_test.pt\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
